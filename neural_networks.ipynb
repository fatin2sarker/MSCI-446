{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 249ms/step - loss: 105322.1719 - mean_absolute_error: 321.3148 - val_loss: 96137.2344 - val_mean_absolute_error: 305.1777\n",
      "Epoch 2/20\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 105465.9609 - mean_absolute_error: 321.7940 - val_loss: 95172.4219 - val_mean_absolute_error: 303.5988\n",
      "Epoch 3/20\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 105205.3438 - mean_absolute_error: 321.5848 - val_loss: 93118.6953 - val_mean_absolute_error: 300.2091\n",
      "Epoch 4/20\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 99696.4609 - mean_absolute_error: 312.1028 - val_loss: 89226.9922 - val_mean_absolute_error: 293.6792\n",
      "Epoch 5/20\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 98224.3047 - mean_absolute_error: 310.3652 - val_loss: 82730.2422 - val_mean_absolute_error: 282.4415\n",
      "Epoch 6/20\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 89117.0547 - mean_absolute_error: 295.0372 - val_loss: 72984.6641 - val_mean_absolute_error: 264.6895\n",
      "Epoch 7/20\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 80999.1562 - mean_absolute_error: 281.1481 - val_loss: 59703.0508 - val_mean_absolute_error: 238.3723\n",
      "Epoch 8/20\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 61934.2070 - mean_absolute_error: 243.7355 - val_loss: 43171.1758 - val_mean_absolute_error: 200.8384\n",
      "Epoch 9/20\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 50233.2812 - mean_absolute_error: 217.6635 - val_loss: 25177.6543 - val_mean_absolute_error: 149.5943\n",
      "Epoch 10/20\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 28005.6914 - mean_absolute_error: 155.5197 - val_loss: 9624.1318 - val_mean_absolute_error: 85.9190\n",
      "Epoch 11/20\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 17263.1777 - mean_absolute_error: 110.9290 - val_loss: 2888.3025 - val_mean_absolute_error: 42.9083\n",
      "Epoch 12/20\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 9359.3242 - mean_absolute_error: 69.4567 - val_loss: 7486.2666 - val_mean_absolute_error: 72.9700\n",
      "Epoch 13/20\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 18357.6699 - mean_absolute_error: 116.4064 - val_loss: 11892.2773 - val_mean_absolute_error: 96.4389\n",
      "Epoch 14/20\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 24401.1973 - mean_absolute_error: 121.9698 - val_loss: 8707.3086 - val_mean_absolute_error: 80.3928\n",
      "Epoch 15/20\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 20252.9023 - mean_absolute_error: 112.0725 - val_loss: 4715.2183 - val_mean_absolute_error: 51.5401\n",
      "Epoch 16/20\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 16843.4180 - mean_absolute_error: 105.1906 - val_loss: 2865.5388 - val_mean_absolute_error: 40.5742\n",
      "Epoch 17/20\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 10139.6377 - mean_absolute_error: 74.0578 - val_loss: 3683.1528 - val_mean_absolute_error: 51.7718\n",
      "Epoch 18/20\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 10059.5547 - mean_absolute_error: 81.2307 - val_loss: 5581.2764 - val_mean_absolute_error: 65.3204\n",
      "Epoch 19/20\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 12604.5977 - mean_absolute_error: 91.5709 - val_loss: 6839.4468 - val_mean_absolute_error: 71.6224\n",
      "Epoch 20/20\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 13037.0176 - mean_absolute_error: 93.9491 - val_loss: 7151.5957 - val_mean_absolute_error: 73.0604\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 11414.1689 - mean_absolute_error: 95.3273\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[11414.1689453125, 95.32728576660156]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Flatten, Dense, Dropout, InputLayer\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('C:/Users/VARDHMAN/Downloads/MSCI-446/updated_cleaned_recipe_dataset.csv')\n",
    "\n",
    "# Data preprocessing\n",
    "# Text processing for 'ingredients'\n",
    "tokenizer = Tokenizer(num_words=10000)\n",
    "tokenizer.fit_on_texts(df['Ingredient'])  \n",
    "sequences = tokenizer.texts_to_sequences(df['Ingredient'])\n",
    "padded_ingredients = pad_sequences(sequences, maxlen=50)\n",
    "\n",
    "# One-hot encoding for 'dietary_info'\n",
    "ohe = OneHotEncoder()\n",
    "dietary_info_encoded = ohe.fit_transform(df[['Dietary Preference']]).toarray()\n",
    "\n",
    "# Combine processed features\n",
    "X = np.concatenate([padded_ingredients, dietary_info_encoded], axis=1)\n",
    "\n",
    "# Assuming 'calories' is a target variable\n",
    "y = df['Calories'].values\n",
    "\n",
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Model building\n",
    "model = Sequential([\n",
    "    InputLayer(shape=(X_train.shape[1],)),\n",
    "    Embedding(input_dim=10000 + 1, output_dim=64),  # Adjust input_dim as needed, remove input_length\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='linear')  \n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mean_absolute_error'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=20, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model\n",
    "model.evaluate(X_test, y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
